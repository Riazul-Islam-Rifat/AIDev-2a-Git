{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bf1f01d-d4a2-4622-b3b2-85b24ada809e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.34.5-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: filelock in d:\\installation\\anaconda\\lib\\site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\installation\\anaconda\\lib\\site-packages (from huggingface_hub) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\installation\\anaconda\\lib\\site-packages (from huggingface_hub) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\installation\\anaconda\\lib\\site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in d:\\installation\\anaconda\\lib\\site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\installation\\anaconda\\lib\\site-packages (from huggingface_hub) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\installation\\anaconda\\lib\\site-packages (from huggingface_hub) (4.9.0)\n",
      "Requirement already satisfied: colorama in d:\\installation\\anaconda\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\installation\\anaconda\\lib\\site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\installation\\anaconda\\lib\\site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\installation\\anaconda\\lib\\site-packages (from requests->huggingface_hub) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\installation\\anaconda\\lib\\site-packages (from requests->huggingface_hub) (2024.2.2)\n",
      "Downloading huggingface_hub-0.34.5-py3-none-any.whl (562 kB)\n",
      "   ---------------------------------------- 0.0/562.2 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/562.2 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 61.4/562.2 kB 1.1 MB/s eta 0:00:01\n",
      "   ------ ------------------------------- 102.4/562.2 kB 980.4 kB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 235.5/562.2 kB 1.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 501.8/562.2 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 562.2/562.2 kB 2.3 MB/s eta 0:00:00\n",
      "Installing collected packages: huggingface_hub\n",
      "Successfully installed huggingface_hub-0.34.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "004253cb-ce11-42bf-aa7f-bebd8402d3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>number</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>agent</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user</th>\n",
       "      <th>state</th>\n",
       "      <th>created_at</th>\n",
       "      <th>closed_at</th>\n",
       "      <th>merged_at</th>\n",
       "      <th>repo_id</th>\n",
       "      <th>repo_url</th>\n",
       "      <th>html_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3264016139</td>\n",
       "      <td>1688</td>\n",
       "      <td>`metta code` --&gt; `metta clip` and additional p...</td>\n",
       "      <td>Remove unused `root_key` variable to fix ruff ...</td>\n",
       "      <td>Claude_Code</td>\n",
       "      <td>37011</td>\n",
       "      <td>jacklionheart</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-07-25T18:15:36Z</td>\n",
       "      <td>2025-07-25T19:17:23Z</td>\n",
       "      <td>2025-07-25T19:17:23Z</td>\n",
       "      <td>843988367.0</td>\n",
       "      <td>https://api.github.com/repos/Metta-AI/metta</td>\n",
       "      <td>https://github.com/Metta-AI/metta/pull/1688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3264021033</td>\n",
       "      <td>41</td>\n",
       "      <td>feat: Comprehensive ruff error resolution with...</td>\n",
       "      <td>## ðŸŽ¯ Mission Accomplished: 100% Ruff Error Res...</td>\n",
       "      <td>Claude_Code</td>\n",
       "      <td>131842369</td>\n",
       "      <td>Draco3310</td>\n",
       "      <td>open</td>\n",
       "      <td>2025-07-25T18:17:57Z</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>992063465.0</td>\n",
       "      <td>https://api.github.com/repos/Draco3310/Gal-Fri...</td>\n",
       "      <td>https://github.com/Draco3310/Gal-Friday2/pull/41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3264042289</td>\n",
       "      <td>1600</td>\n",
       "      <td>Add Evals frontend implementation plan and HTM...</td>\n",
       "      <td>\\nCreate comprehensive implementation plan for...</td>\n",
       "      <td>Claude_Code</td>\n",
       "      <td>6766889</td>\n",
       "      <td>justicart</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-07-25T18:26:15Z</td>\n",
       "      <td>2025-07-25T23:19:14Z</td>\n",
       "      <td>None</td>\n",
       "      <td>926711750.0</td>\n",
       "      <td>https://api.github.com/repos/bolt-foundry/bolt...</td>\n",
       "      <td>https://github.com/bolt-foundry/bolt-foundry/p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  number                                              title  \\\n",
       "0  3264016139    1688  `metta code` --> `metta clip` and additional p...   \n",
       "1  3264021033      41  feat: Comprehensive ruff error resolution with...   \n",
       "2  3264042289    1600  Add Evals frontend implementation plan and HTM...   \n",
       "\n",
       "                                                body        agent    user_id  \\\n",
       "0  Remove unused `root_key` variable to fix ruff ...  Claude_Code      37011   \n",
       "1  ## ðŸŽ¯ Mission Accomplished: 100% Ruff Error Res...  Claude_Code  131842369   \n",
       "2  \\nCreate comprehensive implementation plan for...  Claude_Code    6766889   \n",
       "\n",
       "            user   state            created_at             closed_at  \\\n",
       "0  jacklionheart  closed  2025-07-25T18:15:36Z  2025-07-25T19:17:23Z   \n",
       "1      Draco3310    open  2025-07-25T18:17:57Z                  None   \n",
       "2      justicart  closed  2025-07-25T18:26:15Z  2025-07-25T23:19:14Z   \n",
       "\n",
       "              merged_at      repo_id  \\\n",
       "0  2025-07-25T19:17:23Z  843988367.0   \n",
       "1                  None  992063465.0   \n",
       "2                  None  926711750.0   \n",
       "\n",
       "                                            repo_url  \\\n",
       "0        https://api.github.com/repos/Metta-AI/metta   \n",
       "1  https://api.github.com/repos/Draco3310/Gal-Fri...   \n",
       "2  https://api.github.com/repos/bolt-foundry/bolt...   \n",
       "\n",
       "                                            html_url  \n",
       "0        https://github.com/Metta-AI/metta/pull/1688  \n",
       "1   https://github.com/Draco3310/Gal-Friday2/pull/41  \n",
       "2  https://github.com/bolt-foundry/bolt-foundry/p...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "df_all_pull_req = pd.read_parquet(\"hf://datasets/hao-li/AIDev/all_pull_request.parquet\")\n",
    "df_all_pull_req.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df083166-2e88-471c-8777-34959f1f451c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of all_pull_request:  (932791, 14)\n",
      "Columns of all_pull_request:  ['id', 'number', 'title', 'body', 'agent', 'user_id', 'user', 'state', 'created_at', 'closed_at', 'merged_at', 'repo_id', 'repo_url', 'html_url']\n"
     ]
    }
   ],
   "source": [
    "print('shape of all_pull_request: ',df_all_pull_req.shape)\n",
    "print(\"Columns of all_pull_request: \", list(df_all_pull_req.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b6a7275-6f88-42fe-b551-a88f07594a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of all_repository:  (116211, 7)\n",
      "Columns of all_repository:  ['id', 'url', 'license', 'full_name', 'language', 'forks', 'stars']\n"
     ]
    }
   ],
   "source": [
    "df_all_repository = pd.read_parquet(\"hf://datasets/hao-li/AIDev/all_repository.parquet\")\n",
    "df_all_repository.head(3)\n",
    "\n",
    "print('shape of all_repository: ',df_all_repository.shape)\n",
    "print(\"Columns of all_repository: \", list(df_all_repository.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d87e418c-8519-40b5-a657-fefba5d1e3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of all_user:  (72189, 5)\n",
      "Columns of all_user:  ['id', 'login', 'followers', 'following', 'created_at']\n"
     ]
    }
   ],
   "source": [
    "df_all_user = pd.read_parquet(\"hf://datasets/hao-li/AIDev/all_user.parquet\")\n",
    "df_all_user.head(3)\n",
    "\n",
    "print('shape of all_user: ',df_all_user.shape)\n",
    "print(\"Columns of all_user: \", list(df_all_user.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0b342e5-4b19-4677-b56c-8e0b56c4957a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of human_pr_task_type:  (6618, 6)\n",
      "Columns of human_pr_task_type:  ['agent', 'id', 'title', 'reason', 'type', 'confidence']\n"
     ]
    }
   ],
   "source": [
    "df_human_pr_task_type = pd.read_parquet(\"hf://datasets/hao-li/AIDev/human_pr_task_type.parquet\")\n",
    "df_human_pr_task_type.head(3)\n",
    "\n",
    "print('shape of human_pr_task_type: ',df_human_pr_task_type.shape)\n",
    "print(\"Columns of human_pr_task_type: \", list(df_human_pr_task_type.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5d4825d-7975-450a-9f8b-9997c1a7c9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of human_pull_request:  (6618, 13)\n",
      "Columns of human_pull_request:  ['id', 'number', 'title', 'user', 'user_id', 'state', 'created_at', 'closed_at', 'merged_at', 'repo_url', 'html_url', 'body', 'agent']\n"
     ]
    }
   ],
   "source": [
    "df_human_pull_request = pd.read_parquet(\"hf://datasets/hao-li/AIDev/human_pull_request.parquet\")\n",
    "df_human_pull_request.head(3)\n",
    "\n",
    "print('shape of human_pull_request: ',df_human_pull_request.shape)\n",
    "print(\"Columns of human_pull_request: \", list(df_human_pull_request.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9acab430-2c41-46fa-937f-e79e6a3af96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of issue:  (4614, 9)\n",
      "Columns of issue:  ['id', 'number', 'title', 'body', 'user', 'state', 'created_at', 'closed_at', 'html_url']\n"
     ]
    }
   ],
   "source": [
    "df_issue = pd.read_parquet(\"hf://datasets/hao-li/AIDev/issue.parquet\")\n",
    "df_issue.head(3)\n",
    "\n",
    "print('shape of issue: ',df_issue.shape)\n",
    "print(\"Columns of issue: \", list(df_issue.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8fa4a93-dc51-4971-b4ff-f0460ab16ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pr_comments:  (39122, 7)\n",
      "Columns of pr_comments:  ['id', 'pr_id', 'user', 'user_id', 'user_type', 'created_at', 'body']\n"
     ]
    }
   ],
   "source": [
    "df_pr_comments = pd.read_parquet(\"hf://datasets/hao-li/AIDev/pr_comments.parquet\")\n",
    "df_pr_comments.head(3)\n",
    "\n",
    "print('shape of pr_comments: ',df_pr_comments.shape)\n",
    "print(\"Columns of pr_comments: \", list(df_pr_comments.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5170d7eb-50f6-4f3f-a51f-ff6dc5d90c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pr_commit_details:  (711923, 14)\n",
      "Columns of pr_commit_details:  ['sha', 'pr_id', 'author', 'committer', 'message', 'commit_stats_total', 'commit_stats_additions', 'commit_stats_deletions', 'filename', 'status', 'additions', 'deletions', 'changes', 'patch']\n"
     ]
    }
   ],
   "source": [
    "df_pr_commit_details = pd.read_parquet(\"hf://datasets/hao-li/AIDev/pr_commit_details.parquet\")\n",
    "df_pr_commit_details.head(3)\n",
    "\n",
    "print('shape of pr_commit_details: ',df_pr_commit_details.shape)\n",
    "print(\"Columns of pr_commit_details: \", list(df_pr_commit_details.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5dcfb695-7044-493a-9d78-4b99849fe2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pr_commits:  (88576, 5)\n",
      "Columns of pr_commits:  ['sha', 'pr_id', 'author', 'committer', 'message']\n"
     ]
    }
   ],
   "source": [
    "df_pr_commits = pd.read_parquet(\"hf://datasets/hao-li/AIDev/pr_commits.parquet\")\n",
    "df_pr_commits.head(3)\n",
    "\n",
    "print('shape of pr_commits: ',df_pr_commits.shape)\n",
    "print(\"Columns of pr_commits: \", list(df_pr_commits.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3ccef13-1c10-4d10-a386-8f2b36dc64d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pr_review_comments:  (19450, 15)\n",
      "Columns of pr_review_comments:  ['id', 'pull_request_review_id', 'user', 'user_type', 'diff_hunk', 'path', 'position', 'original_position', 'commit_id', 'original_commit_id', 'body', 'pull_request_url', 'created_at', 'updated_at', 'in_reply_to_id']\n"
     ]
    }
   ],
   "source": [
    "df_pr_review_comments = pd.read_parquet(\"hf://datasets/hao-li/AIDev/pr_review_comments.parquet\")\n",
    "df_pr_review_comments.head(3)\n",
    "\n",
    "print('shape of pr_review_comments: ',df_pr_review_comments.shape)\n",
    "print(\"Columns of pr_review_comments: \", list(df_pr_review_comments.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03e9d1f6-0396-4906-9ef5-a45f106a23e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pr_reviews:  (28875, 7)\n",
      "Columns of pr_reviews:  ['id', 'pr_id', 'user', 'user_type', 'state', 'submitted_at', 'body']\n"
     ]
    }
   ],
   "source": [
    "df_pr_reviews = pd.read_parquet(\"hf://datasets/hao-li/AIDev/pr_reviews.parquet\")\n",
    "df_pr_reviews.head(3)\n",
    "\n",
    "print('shape of pr_reviews: ',df_pr_reviews.shape)\n",
    "print(\"Columns of pr_reviews: \", list(df_pr_reviews.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4fa6bfc-3b82-4605-b0d9-b530eb1d4995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pr_task_type:  (33596, 6)\n",
      "Columns of pr_task_type:  ['agent', 'id', 'title', 'reason', 'type', 'confidence']\n"
     ]
    }
   ],
   "source": [
    "df_pr_task_type = pd.read_parquet(\"hf://datasets/hao-li/AIDev/pr_task_type.parquet\")\n",
    "df_pr_task_type.head(3)\n",
    "\n",
    "print('shape of pr_task_type: ',df_pr_task_type.shape)\n",
    "print(\"Columns of pr_task_type: \", list(df_pr_task_type.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fdd9890-095e-448e-bcec-4c7ffeb064c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pr_timeline:  (325500, 8)\n",
      "Columns of pr_timeline:  ['pr_id', 'event', 'commit_id', 'created_at', 'actor', 'assignee', 'label', 'message']\n"
     ]
    }
   ],
   "source": [
    "df_pr_timeline = pd.read_parquet(\"hf://datasets/hao-li/AIDev/pr_timeline.parquet\")\n",
    "df_pr_timeline.head(3)\n",
    "\n",
    "print('shape of pr_timeline: ',df_pr_timeline.shape)\n",
    "print(\"Columns of pr_timeline: \", list(df_pr_timeline.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3dbb3531-6e00-419a-8bf4-ce813ffeff53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pull_request:  (33596, 14)\n",
      "Columns of pull_request:  ['id', 'number', 'title', 'body', 'agent', 'user_id', 'user', 'state', 'created_at', 'closed_at', 'merged_at', 'repo_id', 'repo_url', 'html_url']\n"
     ]
    }
   ],
   "source": [
    "df_pull_request = pd.read_parquet(\"hf://datasets/hao-li/AIDev/pull_request.parquet\")\n",
    "df_pull_request.head(3)\n",
    "\n",
    "print('shape of pull_request: ',df_pull_request.shape)\n",
    "print(\"Columns of pull_request: \", list(df_pull_request.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "616c4730-2a2d-40bc-b170-2b1229c4bc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of related_issue:  (4923, 3)\n",
      "Columns of related_issue:  ['pr_id', 'issue_id', 'source']\n"
     ]
    }
   ],
   "source": [
    "df_related_issue = pd.read_parquet(\"hf://datasets/hao-li/AIDev/related_issue.parquet\")\n",
    "df_related_issue.head(3)\n",
    "\n",
    "print('shape of related_issue: ',df_related_issue.shape)\n",
    "print(\"Columns of related_issue: \", list(df_related_issue.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36ef7398-9bea-4465-8fa8-1c6e5869085e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of repository:  (2807, 7)\n",
      "Columns of repository:  ['id', 'url', 'license', 'full_name', 'language', 'forks', 'stars']\n"
     ]
    }
   ],
   "source": [
    "df_repository = pd.read_parquet(\"hf://datasets/hao-li/AIDev/repository.parquet\")\n",
    "df_repository.head(3)\n",
    "\n",
    "print('shape of repository: ',df_repository.shape)\n",
    "print(\"Columns of repository: \", list(df_repository.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333b4448-d0ef-4886-8fd4-8218aa634075",
   "metadata": {},
   "source": [
    "# Atempt 1 \n",
    "\n",
    "# Libraries Used: Pandas, NumPy, Matplotlib, Seaborn, Scipy, Sentence-Transformers (PyTorch backend)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86a4785d-6f56-40f0-8765-fe850a4509dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. ... Installed .. .. \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "print('.. ... Installed .. .. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c07b95-2d12-40d8-9945-8f1d0a33ed0d",
   "metadata": {},
   "source": [
    "# Creating a merged dataset (pr_commit_details + pull_request) for quatitative and qualitative analysis.\n",
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82667626-8cac-40c7-b35d-4c232d581771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating file-level changes to PR-level...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pr_id</th>\n",
       "      <th>total_additions</th>\n",
       "      <th>total_deletions</th>\n",
       "      <th>files_touched</th>\n",
       "      <th>total_changes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2756921963</td>\n",
       "      <td>848.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2757103560</td>\n",
       "      <td>517.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>16</td>\n",
       "      <td>779.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pr_id  total_additions  total_deletions  files_touched  total_changes\n",
       "0  2756921963            848.0            344.0             15         1192.0\n",
       "1  2757103560            517.0            262.0             16          779.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating PR-level summary from commit details\n",
    "print(\"Aggregating file-level changes to PR-level...\")\n",
    "pr_level_changes = df_pr_commit_details.groupby('pr_id').agg(\n",
    "    total_additions=('additions', 'sum'),\n",
    "    total_deletions=('deletions', 'sum'),\n",
    "    files_touched=('filename', 'nunique'),\n",
    "    total_changes=('changes', 'sum')\n",
    ").reset_index()\n",
    "pr_level_changes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4fdbd0-1c84-4c27-a08f-1a66d08b9dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
